---
title: "Social Media"
author: "Shubham Bhargava"
date: "2024-03-25"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}

library(readxl)
library(dplyr)
library(FactoMineR)
library(factoextra)

social_media <- read_excel("social_media_cleaned.xlsx")

social_media_numeric <- select_if(social_media, is.numeric)

# Perform PCA
pca_result <- prcomp(social_media_numeric, scale = TRUE)

# Scree plot
plot(pca_result$sdev^2, type = "b", xlab = "Principal Component", ylab = "Variance Explained")


#From PCA variate representation of each PC, Itâ€™s evident that PC1 and PC2 add arround 50% of the to total variance

plot(pca_result$sdev^2, xlab = "Component number", ylab = "Component variance", type = "l", main = "Scree diagram")

# Loadings
loadings <- pca_result$rotation
print(loadings)

# Data projection onto all PCs
data_projection_all <- as.data.frame(pca_result$x)

# Matrix scatterplot for pairs of principal components
pairs(data_projection_all, col = "blue", pch = 19,
      main = "Data Visualization using All PCs")

# Visualize Eigenvalues
fviz_eig(pca_result, addlabels = TRUE)

# Visualize Variable Quality
fviz_pca_var(pca_result, col.var = "cos2",
             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"), 
             repel = TRUE)

# Visualize Individual Contributions
fviz_pca_ind(pca_result,
             geom.ind = "point", # Show points only
             palette = c("#00AFBB", "#E7B800", "#FC4E07"),
             addEllipses = TRUE, # Concentration ellipses
             legend.title = "Groups"
             )

# Biplot
biplot(pca_result)

# Variable correlation plot (Correlation Circle)
fviz_pca_var(pca_result, col.var = "black")

# Quality of representation of variables on dimensions 1 and 2
fviz_cos2(pca_result, choice = "var", axes = 1:2)

# Contributions of variables to principal components
fviz_contrib(pca_result, choice = "var", axes = 1, top = 10)
fviz_contrib(pca_result, choice = "var", axes = 2, top = 10)

# Visualize individual contributions
fviz_pca_ind(pca_result,
             geom.ind = "point", # Show points only
             palette = c("#00AFBB", "#E7B800", "#FC4E07"),
             addEllipses = TRUE, # Concentration ellipses
             legend.title = "Groups"
             )

library(scatterplot3d)
scatterplot3d(pca_result$x[,1:3], color = social_media$Instagram)


```



### Logistic Regression Analysis
<p>To perform logistic regression analysis, we will use the glm() function.</p>

* Load all necessary packages 
* Load Data. we Used read_excel() function to read data from excel
* Now we will use glm() function to fit a logistic regression model to the data.
* Now use summary() function for logistic regression model to view coefficients, standard errors, z-values, and p-values.
* For Residual Analysis use plot() function to get Plot diagnostic plots, including residuals vs. fitted values, QQ plot of residuals, and scale-location plot, to check for homoscedasticity and normality of residuals.

#### Model Development
```{r}
library(readxl)
library(dplyr)
library(ROCR)
library(pROC)

social_media <- read_excel("social_media_cleaned.xlsx")
social_media_numeric <- select_if(social_media, is.numeric)
```

```{r}
threshold <- 200

social_media$tfs_Binary <- ifelse(social_media$Trouble_falling_asleep > threshold, 1, 0)

logit_model <- glm(tfs_Binary ~  Instagram + LinkedIn + SnapChat + Twitter + youtube + OTT + `Whatsapp/Wechat`, data = social_media, 
                    family = binomial)

```

<p>The code reads a dataset and preprocesses it to create a binary outcome variable based on a threshold.</p>
<p>It fits a logistic regression model using three predictor variables: <p>Total_Sessions, Conversion_Rate, and Avg_Session_Duration.</p>
This model development process involves specifying the model formula, fitting the model to the data, and obtaining a summary of the model's coefficients and statistical significance.</p>

#### Model Acceptance
```{r}
summary(logit_model)
anova(logit_model)
```

<p>The coefficients represent the estimated effect of each predictor variable on the log-odds of the outcome variable being in the positive class (1).</p>

<p>For example, the coefficient for Total_Sessions is approximately 0.0002231, indicating that for each unit increase in Total_Sessions, the log-odds of the outcome variable being in the positive class increases by 0.0002231 units.</p>

<p>The coefficients for Conversion_Rate and Avg_Session_Duration are 1.1609186 and -0.1110208, respectively.</p>

#### Residual Analysis
```{r}
# Residual Analysis
residuals(logit_model)
plot(logit_model)
```
<p>Function calculates the residuals for the fitted logistic regression model (logit_model). It returns a vector containing the residuals.</p>
<p>Plot() function generates diagnostic plots for the logistic regression model (logit_model).diagnostic plots including residuals vs. fitted values, quantile-quantile (Q-Q) plot, and leverage plot  </p>

#### Prediction
```{r}s

```

#### Model Accuracy
```{r}
predicted <- predict(logit_model, type = "response")
predicted_binary <- ifelse(predicted > 0.5, 1, 0)
confusion <- table(predicted_binary, social_media$tfs_Binary)
accuracy <- sum(diag(confusion)) / sum(confusion)
print(accuracy)
```
<p>The code reads a dataset from an Excel file, preprocesses it to create a binary outcome variable based on a threshold, fits a logistic regression model to predict this outcome using three predictor variables, conducts residual analysis, evaluates model performance using ROC curve and calculates AUC, makes predictions for a subset of the data, and assesses model accuracy metrics including accuracy and precision.</p>


